{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6819cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Grouper\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import matrixprofile as mp\n",
    "from matplotlib.patches import Rectangle\n",
    "from fbprophet import Prophet\n",
    "from prophet.plot import plot_yearly\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from numpy import sqrt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f2c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_origen(origen,destino):    \n",
    "    \n",
    "    ######################PICKLE 1###############################\n",
    "    with open('/home/jonathan/tesis/3er_avance/columns_names_confinamiento1.pickle', \"rb\") as file:   \n",
    "        columns_names = pickle.load(file)\n",
    "\n",
    "    names = list(columns_names)\n",
    "    lista=[\"ds\"]\n",
    "\n",
    "    for trayectos in names:    \n",
    "        x=trayectos.startswith(origen)    \n",
    "        if x==True:                         \n",
    "            lista.append(trayectos)\n",
    "    \n",
    "    df1 = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento1.csv\", sep=',',index_col=0, parse_dates=True, usecols=lista)\n",
    "    \n",
    "    #Filtramos el destino\n",
    "    columns_names_df = df1.columns   \n",
    "    names_1 = list(columns_names_df)     \n",
    "    \n",
    "    listaDst=[\"ds\"]\n",
    "    for trayectos in names_1:            \n",
    "        x=trayectos.split(\"-\",1)[1]        \n",
    "        if x==destino:                         \n",
    "            listaDst.append(trayectos)            \n",
    "    \n",
    "    df1_Final = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento1.csv\", sep=',',index_col=0, parse_dates=True, usecols=listaDst)   \n",
    "    \n",
    "    ######################PICKLE 2###############################\n",
    "    with open('/home/jonathan/tesis/3er_avance/columns_names_confinamiento2.pickle', \"rb\") as file:   \n",
    "        columns_names = pickle.load(file)\n",
    "\n",
    "    names = list(columns_names)\n",
    "    lista=[\"ds\"]\n",
    "\n",
    "    for trayectos in names:    \n",
    "        x=trayectos.startswith(origen)    \n",
    "        if x==True:                         \n",
    "            lista.append(trayectos)\n",
    "    \n",
    "    df2 = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento2.csv\", sep=',',index_col=0, parse_dates=True, usecols=lista)\n",
    "    \n",
    "    #Filtramos el destino\n",
    "    columns_names_df = df2.columns   \n",
    "    names_1 = list(columns_names_df)     \n",
    "    \n",
    "    listaDst=[\"ds\"]\n",
    "    for trayectos in names_1:            \n",
    "        x=trayectos.split(\"-\",1)[1]        \n",
    "        if x==destino:                         \n",
    "            listaDst.append(trayectos)           \n",
    "    \n",
    "    df2_Final = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento2.csv\", sep=',',index_col=0, parse_dates=True, usecols=listaDst)   \n",
    "    \n",
    "    ######################PICKLE 3###############################\n",
    "    with open('/home/jonathan/tesis/3er_avance/columns_names_confinamiento3.pickle', \"rb\") as file:   \n",
    "        columns_names = pickle.load(file)\n",
    "\n",
    "    names = list(columns_names)\n",
    "    lista=[\"ds\"]\n",
    "\n",
    "    for trayectos in names:    \n",
    "        x=trayectos.startswith(origen)    \n",
    "        if x==True:                         \n",
    "            lista.append(trayectos)\n",
    "    \n",
    "    df3 = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento3.csv\", sep=',',index_col=0, parse_dates=True, usecols=lista)\n",
    "    \n",
    "    #Filtramos el destino\n",
    "    columns_names_df = df3.columns   \n",
    "    names_1 = list(columns_names_df)     \n",
    "    \n",
    "    listaDst=[\"ds\"]\n",
    "    for trayectos in names_1:            \n",
    "        x=trayectos.split(\"-\",1)[1]        \n",
    "        if x==destino:                         \n",
    "            listaDst.append(trayectos)            \n",
    "    \n",
    "    df3_Final = pd.read_csv(\"/home/jonathan/tesis/3er_avance/Trayectos_Periodo_Confinamiento3.csv\", sep=',',index_col=0, parse_dates=True, usecols=listaDst)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df1_Final['Fecha'] = df1_Final.index.date\n",
    "    df1_Final['Año'] = df1_Final.index.year                                \n",
    "    df1_Final['Mes'] = df1_Final.index.month                               \n",
    "    df1_Final['ID_Dia'] = df1_Final.index.dayofweek\n",
    "    df1_Final['Hora'] = df1_Final.index.hour\n",
    "    df1_Final['WeekNo'] = df1_Final.index.isocalendar().week\n",
    "    \n",
    "    df2_Final['Fecha'] = df2_Final.index.date\n",
    "    df2_Final['Año'] = df2_Final.index.year                                \n",
    "    df2_Final['Mes'] = df2_Final.index.month                               \n",
    "    df2_Final['ID_Dia'] = df2_Final.index.dayofweek\n",
    "    df2_Final['Hora'] = df2_Final.index.hour\n",
    "    df2_Final['WeekNo'] = df2_Final.index.isocalendar().week\n",
    "    \n",
    "    df3_Final['Fecha'] = df3_Final.index.date\n",
    "    df3_Final['Año'] = df3_Final.index.year                                \n",
    "    df3_Final['Mes'] = df3_Final.index.month                               \n",
    "    df3_Final['ID_Dia'] = df3_Final.index.dayofweek\n",
    "    df3_Final['Hora'] = df3_Final.index.hour\n",
    "    df3_Final['WeekNo'] = df3_Final.index.isocalendar().week\n",
    "    \n",
    "    return df1, lista, df2, df3, df1_Final,df2_Final,df3_Final, listaDst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "origen = \"2807905\"\n",
    "destino = \"2807901\"\n",
    "df1, lista, df2, df3, df1_Final,df2_Final,df3_Final, listaDst = df_origen(origen,destino)\n",
    "df1_Final.head(5)\n",
    "df2_Final.head(5)\n",
    "df3_Final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a612c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos intervalos de datos por periodos\n",
    "data1=df1_Final.loc['2020-03-16':'2020-04-15']\n",
    "data2=df1_Final.loc['2020-04-16':'2020-05-15']\n",
    "data3=df1_Final.loc['2020-05-01':'2020-05-31']\n",
    "data4=df2_Final.loc['2020-06-01':'2020-06-30']\n",
    "data5=df2_Final.loc['2020-07-01':'2020-07-31']\n",
    "data6=df3_Final.loc['2020-08-01':'2020-08-31']\n",
    "data6.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9fa438",
   "metadata": {},
   "source": [
    "# Agregamos datos del viernes anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo hacemos en otro dataframe que tenga todos los datos y se exporta el archivo csv como se hizo con los datos de temperatura\n",
    "# for i in range(24,0,-24):\n",
    "#     Lunes['t-'+str(i)] = Lunes[\"y\"].shift(i)\n",
    "#     Lunes = Lunes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Creamos tablas con cada uno de los principales trayectos\n",
    "lista_periodos=[1,2,3,4,5,6]    \n",
    "dict_dias={0:\"Monday\",1:\"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"}\n",
    "        \n",
    "for periodo in lista_periodos:        \n",
    "    cont=0\n",
    "    globals()[f\"d{periodo}\"] = globals()[f\"data{periodo}\"].reset_index()                                \n",
    "    globals()[f\"df_{periodo}\"] = pd.DataFrame(data=globals()[f\"d{periodo}\"], columns=['ds',listaDst[1],'Hora','Fecha','WeekNo','ID_Dia'])\n",
    "    globals()[f\"df_{periodo}\"].set_index([listaDst[1]], inplace = True) \n",
    "    \n",
    "    for dia in dict_dias:        \n",
    "        globals()[f\"df_{dict_dias[dia]}_{periodo}\"] = globals()[f\"df_{periodo}\"].loc[globals()[f\"df_{periodo}\"].loc[:,'ID_Dia'] == cont]  # Seleccionamos solo los datos del lunes o solo los datos del martes para crear nuevas tablas dependiendo del día        \n",
    "        globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"] = pd.DataFrame({})  #Creamos un nuevo dataframe vacio\n",
    "        globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"] = globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].append(globals()[f\"df_{dict_dias[dia]}_{periodo}\"])  #Guardamos en el dataframe vacio cada una de las tablas, hay tabla lunes, tabla martes..\n",
    "        \n",
    "        #Seleccionamos celdas del dataframe para generar las fechas que se requieren graficar\n",
    "        start = globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].iloc[0]['Fecha'] #Primera celda de la columna fecha\n",
    "        period_start = globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].iloc[0]['WeekNo']\n",
    "        period_end = globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].at[globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].index[-1],'WeekNo']  #última celda de columna WeekNo\n",
    "        \n",
    "        #Condición de error en period_start/period_end\n",
    "        if (type(period_start) == pd.core.series.Series) | (type(period_end) == pd.core.series.Series):    \n",
    "            lista = list(period_end)\n",
    "            period_end = lista[-1]        \n",
    "        \n",
    "        periods = list(range(period_start, period_end+1))\n",
    "\n",
    "        #Obtenemos las fechas de cada día \n",
    "        date_generated = pd.date_range(start, periods=len(periods), freq='7D')\n",
    "        \n",
    "        #Creamos una tabla para cada fecha de cada lunes o de cada martes..\n",
    "        cont2=1        \n",
    "        for date in date_generated:            \n",
    "            globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}_{cont2}\"] = globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].loc[globals()[f\"filtrado_Data_{dict_dias[dia]}_{periodo}\"].loc[:,'Fecha'] == date]\n",
    "            cont2=cont2+1\n",
    "        cont=cont+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdaa642",
   "metadata": {},
   "outputs": [],
   "source": [
    "period1 = filtrado_Data_Monday_3\n",
    "period2 = filtrado_Data_Monday_4\n",
    "period3 = filtrado_Data_Monday_5\n",
    "period4 = filtrado_Data_Monday_6\n",
    "Lunes = pd.concat([period1,period2,period3,period4])\n",
    "start_date = pd.Timestamp('2020-05-02')\n",
    "end_date = pd.Timestamp('2020-08-31')\n",
    "mask = (Lunes['Fecha'] >= start_date) & (Lunes['Fecha'] <= end_date)\n",
    "Lunes = Lunes.loc[mask]\n",
    "Lunes = Lunes.reset_index()\n",
    "Lunes = Lunes.set_index([\"ds\"])\n",
    "Lunes.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e32424",
   "metadata": {},
   "source": [
    "# Preparamos los datos \n",
    "## Dividimos el periodo 1 en 2 subconjuntos - Desescalada y Nueva normalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c340cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lunes = Lunes.drop(columns=['Fecha','ID_Dia','WeekNo'])\n",
    "Lunes = Lunes.reset_index()\n",
    "Lunes = Lunes.rename(columns={'2807905-2807901':'y'})\n",
    "# Lunes.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fe202",
   "metadata": {},
   "source": [
    "## Agregamos columnas del Lunes anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(24,0,-24):\n",
    "    Lunes['t-'+str(i)] = Lunes[\"y\"].shift(i)\n",
    "    Lunes = Lunes.fillna(0)\n",
    "    # PeriodoNnormalidad=PeriodoNnormalidad.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Lunes.tail(73))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead3d9d",
   "metadata": {},
   "source": [
    "## Desescalada: 2 Mayo - 8 Junio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6901dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2020-05-02')\n",
    "end_date = pd.Timestamp('2020-06-08 23:00:00')\n",
    "mask = (Lunes['ds'] >= start_date) & (Lunes['ds'] <= end_date)\n",
    "PeriodoDesescalada = Lunes.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e41a92",
   "metadata": {},
   "source": [
    "## Nueva normalidad: 9 Junio - 31 Agosto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2020-06-09')\n",
    "end_date = pd.Timestamp('2020-08-31 23:00:00')\n",
    "mask = (Lunes['ds'] >= start_date) & (Lunes['ds'] <= end_date)\n",
    "PeriodoNnormalidad = Lunes.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798befdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PeriodoNnormalidad1 = PeriodoNnormalidad.loc[PeriodoNnormalidad.loc[:,'Hora'] <= 9 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff84261",
   "metadata": {},
   "source": [
    "# Agregamos columnas de días anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estos archivos csv están filtrados en Lunes y en Hora para que queden de igual tamaño.\n",
    "MartesBack = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/MartesBack.csv\", sep=',')\n",
    "MiercolesBack = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/MiercolesBack.csv\", sep=',')\n",
    "JuevesBack = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/JuevesBack.csv\", sep=',')\n",
    "ViernesBack = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/ViernesBack.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PeriodoNnormalidad1 = PeriodoNnormalidad1.reset_index()\n",
    "PeriodoNnormalidad1 = PeriodoNnormalidad1.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254eb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PeriodoNnormalidad1['MarBack'] = MartesBack.MarBack\n",
    "PeriodoNnormalidad1['MierBack'] = MiercolesBack.MierBack\n",
    "PeriodoNnormalidad1['JueBack'] = JuevesBack.JueBack\n",
    "PeriodoNnormalidad1['VieBack'] = ViernesBack.VieBack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aee5a2",
   "metadata": {},
   "source": [
    "# Agregamos columnas de Temperatura y Precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTemp = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/DataTempMayAgo.csv\", sep=',',index_col=0, parse_dates=True)\n",
    "DataPrec = pd.read_csv(\"/home/jonathan/tesis/8vo_avance/DataPrecMayAgo.csv\", sep=',',index_col=0, parse_dates=True)\n",
    "DataTemp['ID_Dia'] = DataTemp.index.dayofweek\n",
    "DataPrec['ID_Dia'] = DataPrec.index.dayofweek\n",
    "DataTemp['Hora'] = DataTemp.index.hour\n",
    "DataPrec['Hora'] = DataPrec.index.hour\n",
    "DataTemp = DataTemp.loc[DataTemp.loc[:,'ID_Dia'] == 0 ]\n",
    "DataPrec = DataPrec.loc[DataPrec.loc[:,'ID_Dia'] == 0 ]\n",
    "DataTemp = DataTemp.loc[DataTemp.loc[:,'Hora'] <= 9 ]\n",
    "DataPrec = DataPrec.loc[DataPrec.loc[:,'Hora'] <= 9 ]\n",
    "\n",
    "start_date = pd.Timestamp('2020-06-09')\n",
    "end_date = pd.Timestamp('2020-08-31 09:00:00')\n",
    "DataTemp = DataTemp.reset_index()\n",
    "mask = (DataTemp['ds'] >= start_date) & (DataTemp['ds'] <= end_date)\n",
    "DataTemp = DataTemp.loc[mask]\n",
    "\n",
    "start_date = pd.Timestamp('2020-06-09')\n",
    "end_date = pd.Timestamp('2020-08-31 09:00:00')\n",
    "DataPrec = DataPrec.reset_index()\n",
    "mask = (DataPrec['ds'] >= start_date) & (DataPrec['ds'] <= end_date)\n",
    "DataPrec = DataPrec.loc[mask]\n",
    "\n",
    "DataTemp = DataTemp.drop(columns=['ID_Dia'])\n",
    "DataPrec = DataPrec.drop(columns=['ID_Dia'])\n",
    "DataTemp = DataTemp.drop(columns=['Hora'])\n",
    "DataPrec = DataPrec.drop(columns=['Hora'])\n",
    "\n",
    "DataTemp = DataTemp.set_index('ds')\n",
    "DataTemp = DataTemp.reset_index()\n",
    "DataPrec = DataPrec.set_index('ds')\n",
    "DataPrec = DataPrec.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba183a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PeriodoNnormalidad1['Temp'] = DataTemp.Temp \n",
    "PeriodoNnormalidad1['Prec'] = DataPrec.Prec \n",
    "PeriodoNnormalidad1.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50179ba8",
   "metadata": {},
   "source": [
    "# Creamos las funciones para agregar columnas al DF Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_Lunes(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0)\n",
    "\n",
    "def est_Viernes(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 4)\n",
    "\n",
    "def est_Lunes1AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 1)\n",
    "\n",
    "def est_Lunes2AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 2)\n",
    "\n",
    "def est_Lunes3AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 3)\n",
    "\n",
    "def est_Lunes4AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 4)\n",
    "\n",
    "def est_Lunes5AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 5)\n",
    "\n",
    "def est_Lunes6AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 6)\n",
    "\n",
    "def est_Lunes7AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 7)\n",
    "\n",
    "def est_Lunes8AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 8)\n",
    "\n",
    "def est_Lunes9AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 9)\n",
    "\n",
    "def est_Lunes10AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 10)\n",
    "\n",
    "def est_Lunes11AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 11)\n",
    "\n",
    "def est_Lunes12PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 12)\n",
    "\n",
    "def est_Lunes13PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 13)\n",
    "\n",
    "def est_Lunes14PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 14)\n",
    "\n",
    "def est_Lunes15PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 15)\n",
    "\n",
    "def est_Lunes16PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 16)\n",
    "\n",
    "def est_Lunes17PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 17)\n",
    "\n",
    "def est_Lunes18PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 18)\n",
    "\n",
    "def est_Lunes19PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 19)\n",
    "\n",
    "def est_Lunes20PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 20)\n",
    "\n",
    "def est_Lunes21PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 21)\n",
    "\n",
    "def est_Lunes22PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 22)\n",
    "\n",
    "def est_Lunes23PM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 23)\n",
    "\n",
    "def est_Lunes24AM(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.dayofweek == 0 and date.hour == 0)\n",
    "\n",
    "##############################################Train########################################################\n",
    "\n",
    "def Regressor1AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 1:                 \n",
    "        mean = Train1AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor2AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 2:                 \n",
    "        mean = Train2AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor3AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 3:                 \n",
    "        mean = Train3AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor4AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 4:                 \n",
    "        mean = Train4AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor5AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 5:                 \n",
    "        mean = Train5AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor6AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 6:                 \n",
    "        mean = Train6AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor7AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 7:                 \n",
    "        mean = Train7AM_N.y.mean()\n",
    "        valor = mean         \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor8AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 8:                 \n",
    "        mean = Train8AM_N.y.mean()\n",
    "        valor = mean                \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor9AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 9:                 \n",
    "        mean = Train9AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor10AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 10:                 \n",
    "        mean = Train10AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor11AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 11:                 \n",
    "        mean = Train11AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor12PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 12:                 \n",
    "        mean = Train12PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor13PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 13:                 \n",
    "        mean = Train13PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor14PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 14:                 \n",
    "        mean = Train14PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor15PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 15:                 \n",
    "        mean = Train15PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor16PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 16:                 \n",
    "        mean = Train16PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor17PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 17:                 \n",
    "        mean = Train17PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor18PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 18:                 \n",
    "        mean = Train18PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor19PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 19:                 \n",
    "        mean = Train19PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor20PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 20:                 \n",
    "        mean = Train20PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor21PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 21:                 \n",
    "        mean = Train21PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor22PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 22:                 \n",
    "        mean = Train22PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor23PMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 23:                 \n",
    "        mean = Train23PM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor24AMTrain(ds):\n",
    "    global fila    \n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.dayofweek == 0 and date.hour == 0:                 \n",
    "        mean = Train24AM_N.y.mean()\n",
    "        valor = mean \n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_SevenBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor\n",
    "    if i == 1:\n",
    "        i2=90\n",
    "    elif i == 2:\n",
    "        i2=100\n",
    "    else:\n",
    "        i2=110\n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['t-24']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    elif date.day != fechaTest.day:    \n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['t-24']        \n",
    "        if fila2 < i2:\n",
    "            fila2 += 1\n",
    "    else:\n",
    "        valor = 0    \n",
    "    return (valor) #print(date),print(valor),print(fechaTest),print(fila2),print(fila))\n",
    "\n",
    "def Regressor_MartesBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['MarBack']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['MarBack']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_MiercolesBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['MierBack']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['MierBack']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_JuevesBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['JueBack']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['JueBack']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_ViernesBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['VieBack']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['VieBack']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_LunMierBack(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor\n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = (valor['t-24'] + valor['MierBack'])/2\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = (valor['t-24'] + valor['MierBack'])/2\n",
    "        fila2 += 1  \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_Temp(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['Temp']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['Temp']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "def Regressor_Prec(ds,i):\n",
    "    global fila\n",
    "    global fila2    \n",
    "    global valor    \n",
    "    date = pd.to_datetime(ds)\n",
    "    fechaTest = globals()[f\"test_data_N{i}\"].ds.iloc[0]\n",
    "    if (date.month == fechaTest.month) and (date.day == fechaTest.day) and (date.year == fechaTest.year):\n",
    "        valor = globals()[f\"test_data_N{i}\"].loc[fila]\n",
    "        valor = valor['Prec']\n",
    "        if fila < 9:\n",
    "            fila += 1\n",
    "    else:\n",
    "        valor = globals()[f\"train_data_N{i}\"].loc[fila2]\n",
    "        valor = valor['Prec']                \n",
    "        fila2 += 1    \n",
    "    return (valor)\n",
    "\n",
    "\n",
    "PeriodoDesescalada['Lunes'] = PeriodoDesescalada['ds'].apply(est_Lunes)\n",
    "PeriodoNnormalidad1['Lunes'] = PeriodoNnormalidad1['ds'].apply(est_Lunes)\n",
    "\n",
    "PeriodoDesescalada['Lunes24AM'] = PeriodoDesescalada['ds'].apply(est_Lunes24AM)\n",
    "PeriodoNnormalidad1['Lunes24AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes24AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes1AM'] = PeriodoDesescalada['ds'].apply(est_Lunes1AM)\n",
    "PeriodoNnormalidad1['Lunes1AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes1AM) \n",
    "\n",
    "PeriodoDesescalada['Lunes2AM'] = PeriodoDesescalada['ds'].apply(est_Lunes2AM)\n",
    "PeriodoNnormalidad1['Lunes2AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes2AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes3AM'] = PeriodoDesescalada['ds'].apply(est_Lunes3AM)\n",
    "PeriodoNnormalidad1['Lunes3AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes3AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes4AM'] = PeriodoDesescalada['ds'].apply(est_Lunes4AM)\n",
    "PeriodoNnormalidad1['Lunes4AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes4AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes5AM'] = PeriodoDesescalada['ds'].apply(est_Lunes5AM)\n",
    "PeriodoNnormalidad1['Lunes5AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes5AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes6AM'] = PeriodoDesescalada['ds'].apply(est_Lunes6AM)\n",
    "PeriodoNnormalidad1['Lunes6AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes6AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes7AM'] = PeriodoDesescalada['ds'].apply(est_Lunes7AM)\n",
    "PeriodoNnormalidad1['Lunes7AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes7AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes8AM'] = PeriodoDesescalada['ds'].apply(est_Lunes8AM)\n",
    "PeriodoNnormalidad1['Lunes8AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes8AM)\n",
    "\n",
    "PeriodoDesescalada['Lunes9AM'] = PeriodoDesescalada['ds'].apply(est_Lunes9AM)\n",
    "PeriodoNnormalidad1['Lunes9AM'] = PeriodoNnormalidad1['ds'].apply(est_Lunes9AM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fef748",
   "metadata": {},
   "source": [
    "## Aplicamos Rolling Forecasting para evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fila = 0\n",
    "fila2 = 0\n",
    "def rolling_forecast(train_data_N,test_data_N,i):       \n",
    "    predictions_rolling = pd.DataFrame({})\n",
    "    history = train_data_N.copy()   # El problema es en history       \n",
    "    cont = 1    \n",
    "    \n",
    "    for t in range(len(test_data_N)):        \n",
    "        global fila \n",
    "        global fila2       \n",
    "              \n",
    "        m = Prophet(weekly_seasonality=False,daily_seasonality=False,\n",
    "                    seasonality_mode='multiplicative')        \n",
    "#         m.add_seasonality(name='Lunes_season', period=1, fourier_order=6, condition_name='Lunes')                \n",
    "#         m.add_regressor('Patron24AM_N',mode='multiplicative')#,mode='additive')#\n",
    "#         m.add_regressor('Patron1AM_N',mode='multiplicative')                        \n",
    "#         m.add_regressor('Patron2AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron3AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron4AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron5AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron6AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron7AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron8AM_N',mode='multiplicative')        \n",
    "#         m.add_regressor('Patron9AM_N',mode='multiplicative')     \n",
    "#         m.add_regressor('t-24',mode='multiplicative')\n",
    "#         m.add_regressor('MarBack',mode='multiplicative')\n",
    "#         m.add_regressor('MierBack',mode='multiplicative')\n",
    "#         m.add_regressor('JueBack',mode='multiplicative')\n",
    "#         m.add_regressor('VieBack',mode='multiplicative')\n",
    "        m.add_regressor('LunMierBack',mode='multiplicative')\n",
    "#         m.add_regressor('Temp',mode='additive')\n",
    "        m.add_regressor('Prec',mode='multiplicative')\n",
    "        \n",
    "        m.fit(history);\n",
    "        \n",
    "        #future es el Dataframe con todas las fEchas de entrenamiento y va agregando fechas futuras en cada ciclo        \n",
    "        if cont <= 1:\n",
    "            future = m.make_future_dataframe(periods=168, freq='H')  # Aqui está el error pasa de largo y repite el valor de la fila 89                        \n",
    "        else:\n",
    "            future = m.make_future_dataframe(periods=1, freq='H')                                    \n",
    "        \n",
    "        #forecast contiene todos los datos de entrenamiento, además va agregando 1 a 1 las predicciones                \n",
    "        if cont <= 1:\n",
    "#             intervalo1 = pd.Timestamp('2020-08-24 09:00:00')\n",
    "            intervalo1 = pd.Timestamp(str(train_data_N.ds.iloc[-1]))\n",
    "#             intervalo2 = pd.Timestamp('2020-08-31 00:00:00')\n",
    "            intervalo2 = pd.Timestamp(str(test_data_N.ds.iloc[0]))\n",
    "            mask = (future['ds'] <= intervalo1) | (future['ds'] == intervalo2)\n",
    "            future = future.loc[mask]                \n",
    "        \n",
    "#         future['Lunes'] = future['ds'].apply(est_Lunes)        \n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['t-24'] = future['ds'].apply(Regressor_SevenBack,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['MarBack'] = future['ds'].apply(Regressor_MartesBack,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['MierBack'] = future['ds'].apply(Regressor_MiercolesBack,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['JueBack'] = future['ds'].apply(Regressor_JuevesBack,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['VieBack'] = future['ds'].apply(Regressor_ViernesBack,i=i)\n",
    "        fila = 0\n",
    "        fila2 = 0\n",
    "        future['LunMierBack'] = future['ds'].apply(Regressor_LunMierBack,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['Temp'] = future['ds'].apply(Regressor_Temp,i=i)\n",
    "        fila = 0\n",
    "        fila2 = 0\n",
    "        future['Prec'] = future['ds'].apply(Regressor_Prec,i=i)\n",
    "#         fila = 0\n",
    "#         fila2 = 0\n",
    "#         future['Patron24AM_N'] = future['ds'].apply(Regressor24AMTrain)                \n",
    "#         future['Patron1AM_N'] = future['ds'].apply(Regressor1AMTrain)           \n",
    "#         future['Patron2AM_N'] = future['ds'].apply(Regressor2AMTrain)        \n",
    "#         future['Patron3AM_N'] = future['ds'].apply(Regressor3AMTrain)        \n",
    "#         future['Patron4AM_N'] = future['ds'].apply(Regressor4AMTrain)\n",
    "#         future['Patron5AM_N'] = future['ds'].apply(Regressor5AMTrain)\n",
    "#         future['Patron6AM_N'] = future['ds'].apply(Regressor6AMTrain)\n",
    "#         future['Patron7AM_N'] = future['ds'].apply(Regressor7AMTrain)\n",
    "#         future['Patron8AM_N'] = future['ds'].apply(Regressor8AMTrain)\n",
    "#         future['Patron9AM_N'] = future['ds'].apply(Regressor9AMTrain) \n",
    "        \n",
    "        print(future.tail(24))             \n",
    "        forecast = m.predict(future)         \n",
    "        output=forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]                                \n",
    "        \n",
    "        # La variable yhat contiene la predicción en cada ciclo \n",
    "        yhat = output[['yhat']][len(history):].values[0][0]  \n",
    "        \n",
    "        yhat2 = output[['ds','yhat']][len(history):]\n",
    "        predictions_rolling = predictions_rolling.append(yhat2)       \n",
    "        \n",
    "        #obs crea un nuevo datafRame en cada ciclo con la fecha a predecir y el valor real\n",
    "        data = {'ds': [test_data_N[['ds']].iloc[t]]}\n",
    "        obs = pd.DataFrame(test_data_N[['ds','y','Prec','LunMierBack']].iloc[t])#,'Temp','Prec','Patron24AM_N','Patron1AM_N','Patron2AM_N','Patron3AM_N','Patron4AM_N','Patron5AM_N','Patron6AM_N','Patron7AM_N','Patron8AM_N','Patron9AM_N']].iloc[t])\n",
    "        \n",
    "        \n",
    "        #history concatena los datos de entrenamiento y los datos de prueba (test)\n",
    "        history = pd.concat([history, obs.transpose()],axis=0) #Hace que el dataframe se actualice con fEchas futuras       \n",
    "        cont += 1\n",
    "        \n",
    "        #print('predicted=%f, expected=%f' % (yhat, obs.transpose()['y']))\n",
    "    figura = m.plot_components(forecast)\n",
    "        \n",
    "    return figura,predictions_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ef7dc",
   "metadata": {},
   "source": [
    "# Datos de prueba y datos de entrenamiento - Llamamos a las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nueva Normalidad\n",
    "PeriodoNnormalidad1 = PeriodoNnormalidad1.set_index('ds')\n",
    "train_end_N1 = datetime.datetime(2020,8,16,9,0,0)\n",
    "test_end_N1 = datetime.datetime(2020,8,17,9,0,0)\n",
    "train_end_N2 = datetime.datetime(2020,8,23,9,0,0)\n",
    "test_end_N2 = datetime.datetime(2020,8,24,9,0,0)\n",
    "train_end_N3 = datetime.datetime(2020,8,30,9,0,0)\n",
    "test_end_N3 = datetime.datetime(2020,8,31,9,0,0)\n",
    "\n",
    "train_data_N1 = PeriodoNnormalidad1[:train_end_N1]\n",
    "test_data_N1 = PeriodoNnormalidad1[train_end_N1 + timedelta(hours=1):test_end_N1]\n",
    "\n",
    "train_data_N2 = PeriodoNnormalidad1[:train_end_N2]\n",
    "test_data_N2 = PeriodoNnormalidad1[train_end_N2 + timedelta(hours=1):test_end_N2]\n",
    "\n",
    "train_data_N3 = PeriodoNnormalidad1[:train_end_N3]\n",
    "test_data_N3 = PeriodoNnormalidad1[train_end_N3 + timedelta(hours=1):test_end_N3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20373301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_N1 = train_data_N1.reset_index()\n",
    "test_data_N1 = test_data_N1.reset_index()\n",
    "train_data_N2 = train_data_N2.reset_index()\n",
    "test_data_N2 = test_data_N2.reset_index()\n",
    "train_data_N3 = train_data_N3.reset_index()\n",
    "test_data_N3 = test_data_N3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_N3.tail(10)\n",
    "train_data_N1.iloc[-5:,0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a766e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_N1.tail()\n",
    "test_data_N1.iloc[-5:,0:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11535b7",
   "metadata": {},
   "source": [
    "# Ajustes para crear los Regresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################PeriodoNnormalidad######################\n",
    "mask24AM_N = (PeriodoNnormalidad1['Lunes24AM'] == True)\n",
    "mask1AM_N = (PeriodoNnormalidad1['Lunes1AM'] == True)\n",
    "mask2AM_N = (PeriodoNnormalidad1['Lunes2AM'] == True)\n",
    "mask3AM_N = (PeriodoNnormalidad1['Lunes3AM'] == True)\n",
    "mask4AM_N = (PeriodoNnormalidad1['Lunes4AM'] == True)\n",
    "mask5AM_N = (PeriodoNnormalidad1['Lunes5AM'] == True)\n",
    "mask6AM_N = (PeriodoNnormalidad1['Lunes6AM'] == True)\n",
    "mask7AM_N = (PeriodoNnormalidad1['Lunes7AM'] == True)\n",
    "mask8AM_N = (PeriodoNnormalidad1['Lunes8AM'] == True)\n",
    "mask9AM_N = (PeriodoNnormalidad1['Lunes9AM'] == True)\n",
    "\n",
    "Train24AM_N = PeriodoNnormalidad1.loc[mask24AM_N]\n",
    "Train1AM_N = PeriodoNnormalidad1.loc[mask1AM_N]\n",
    "Train2AM_N = PeriodoNnormalidad1.loc[mask2AM_N]\n",
    "Train3AM_N = PeriodoNnormalidad1.loc[mask3AM_N]\n",
    "Train4AM_N = PeriodoNnormalidad1.loc[mask4AM_N]\n",
    "Train5AM_N = PeriodoNnormalidad1.loc[mask5AM_N]\n",
    "Train6AM_N = PeriodoNnormalidad1.loc[mask6AM_N]\n",
    "Train7AM_N = PeriodoNnormalidad1.loc[mask7AM_N]\n",
    "Train8AM_N = PeriodoNnormalidad1.loc[mask8AM_N]\n",
    "Train9AM_N = PeriodoNnormalidad1.loc[mask9AM_N]\n",
    "\n",
    "# Depuramos nuestra tabla final eliminando columnas que no son necesarias para la predicción\n",
    "train_data_N1 = train_data_N1.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])\n",
    "train_data_N2 = train_data_N2.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])\n",
    "train_data_N3 = train_data_N3.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])\n",
    "test_data_N1 = test_data_N1.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])\n",
    "test_data_N2 = test_data_N2.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])\n",
    "test_data_N3 = test_data_N3.drop(columns=['Lunes24AM','Lunes1AM','Lunes2AM','Lunes3AM','Lunes4AM','Lunes5AM','Lunes6AM','Lunes7AM','Lunes8AM','Lunes9AM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento\n",
    "for it in range(1,4):\n",
    "    fila = 0\n",
    "    fila2 = 0\n",
    "    globals()[f\"train_data_N{it}\"]['LunMierBack'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor_LunMierBack,i=it)    \n",
    "    globals()[f\"train_data_N{it}\"]['Patron24AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor24AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron1AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor1AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron2AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor2AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron3AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor3AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron4AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor4AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron5AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor5AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron6AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor6AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron7AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor7AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron8AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor8AMTrain)\n",
    "    globals()[f\"train_data_N{it}\"]['Patron9AM_N'] = globals()[f\"train_data_N{it}\"]['ds'].apply(Regressor9AMTrain)    \n",
    "    \n",
    "\n",
    "    #####################################Test#####################################\n",
    "    globals()[f\"test_data_N{it}\"]['LunMierBack'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor_LunMierBack,i=it)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron24AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor24AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron1AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor1AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron2AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor2AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron3AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor3AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron4AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor4AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron5AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor5AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron6AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor6AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron7AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor7AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron8AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor8AMTrain)\n",
    "    globals()[f\"test_data_N{it}\"]['Patron9AM_N'] = globals()[f\"test_data_N{it}\"]['ds'].apply(Regressor9AMTrain)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52014682",
   "metadata": {},
   "outputs": [],
   "source": [
    "figura1,predictions1 = rolling_forecast(train_data_N1, test_data_N1, i=1) # Variable i para crear las \n",
    "figura2,predictions2 = rolling_forecast(train_data_N2, test_data_N2, i=2)\n",
    "figura3,predictions3 = rolling_forecast(train_data_N3, test_data_N3, i=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = predictions1.set_index('ds')\n",
    "test_data_N1 = test_data_N1.set_index('ds')\n",
    "predictions2 = predictions2.set_index('ds')\n",
    "test_data_N2 = test_data_N2.set_index('ds')\n",
    "predictions3 = predictions3.set_index('ds')\n",
    "test_data_N3 = test_data_N3.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03cfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Create and style traces\n",
    "fig.add_trace(go.Scatter(x=test_data_N1.index, y=test_data_N1.y, name='Actual',))\n",
    "fig.add_trace(go.Scatter(x=predictions1.index, y=predictions1.yhat, name='Predicted',))\n",
    "# fig.add_trace(go.Scatter(x=predictions1.index, y=predictions1.Temp, name='Temp',))\n",
    "# fig.add_trace(go.Scatter(x=predictions1.index, y=predictions1.Prec, name='Prec',))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75604138",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Create and style traces\n",
    "fig.add_trace(go.Scatter(x=test_data_N2.index, y=test_data_N2.y, name='Actual',))\n",
    "fig.add_trace(go.Scatter(x=predictions2.index, y=predictions2.yhat, name='Predicted',))\n",
    "# fig.add_trace(go.Scatter(x=predictions2.index, y=predictions2.Temp, name='Temp',))\n",
    "# fig.add_trace(go.Scatter(x=predictions2.index, y=predictions2.Prec, name='Prec',))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Create and style traces\n",
    "fig.add_trace(go.Scatter(x=test_data_N3.index, y=test_data_N3.y, name='Actual',))\n",
    "fig.add_trace(go.Scatter(x=predictions3.index, y=predictions3.yhat, name='Predicted',))\n",
    "# fig.add_trace(go.Scatter(x=predictions3.index, y=predictions3.Temp, name='Temp',))\n",
    "# fig.add_trace(go.Scatter(x=predictions3.index, y=predictions3.Prec, name='Prec',))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals1 = test_data_N1['y'] - predictions1['yhat']\n",
    "residuals1 = residuals1.to_frame(name='residual_rolling')\n",
    "residuals2 = test_data_N2['y'] - predictions2['yhat']\n",
    "residuals2 = residuals2.to_frame(name='residual_rolling')\n",
    "residuals3 = test_data_N3['y'] - predictions3['yhat']\n",
    "residuals3 = residuals3.to_frame(name='residual_rolling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c60bb",
   "metadata": {},
   "source": [
    "# Obtenemos lás métricas por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c02fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1 = sqrt(mean_squared_error(test_data_N1.y, predictions1.yhat))\n",
    "RMSE2 = sqrt(mean_squared_error(test_data_N2.y, predictions2.yhat))\n",
    "RMSE3 = sqrt(mean_squared_error(test_data_N3.y, predictions3.yhat))\n",
    "print(\"RMSE1:\",RMSE1)\n",
    "print(\"RMSE2:\",RMSE2)\n",
    "print(\"RMSE3:\",RMSE3)\n",
    "R2_1 = r2_score(test_data_N1.y, predictions1.yhat,multioutput='variance_weighted')\n",
    "R2_2 = r2_score(test_data_N2.y, predictions2.yhat,multioutput='variance_weighted')\n",
    "R2_3 = r2_score(test_data_N3.y, predictions3.yhat,multioutput='variance_weighted')\n",
    "print(\"R2_1:\",R2_1)\n",
    "print(\"R2_2:\",R2_2)\n",
    "print(\"R2_3:\",R2_3)\n",
    "Wmape1 = np.sum(abs(predictions1['yhat']-test_data_N1['y']))/np.sum(abs(test_data_N1['y']))*100\n",
    "Wmape2 = np.sum(abs(predictions2['yhat']-test_data_N2['y']))/np.sum(abs(test_data_N2['y']))*100\n",
    "Wmape3 = np.sum(abs(predictions3['yhat']-test_data_N3['y']))/np.sum(abs(test_data_N3['y']))*100\n",
    "print(Wmape1)\n",
    "print(Wmape2)\n",
    "print(Wmape3)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Los siguientes métricas no concuerdan con el valor RMSE\")\n",
    "print('MAPE1:', round(np.mean(abs(residuals1['residual_rolling']/test_data_N1['y']))*100,4))\n",
    "print('MAPE2:', round(np.mean(abs(residuals2['residual_rolling']/test_data_N2['y']))*100,4))\n",
    "print('MAPE3:', round(np.mean(abs(residuals3['residual_rolling']/test_data_N3['y']))*100,4))\n",
    "\n",
    "print('SMAPE1:', round((1/len(test_data_N1) * np.sum(abs(residuals1['residual_rolling']) / (abs(test_data_N1.y)+abs(predictions1.yhat))*100)),2))\n",
    "print('SMAPE2:', round((1/len(test_data_N2) * np.sum(abs(residuals2['residual_rolling']) / (abs(test_data_N2.y)+abs(predictions2.yhat))*100)),2))\n",
    "print('SMAPE3:', round((1/len(test_data_N3) * np.sum(abs(residuals3['residual_rolling']) / (abs(test_data_N3.y)+abs(predictions3.yhat))*100)),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_coeff = (predictions3['yhat']-test_data_N3['y'])/(predictions3['yhat'] - test_data_N3['y']).mean()\n",
    "# print(weighted_coeff)\n",
    "# Wmape = (np.sum((predictions3['yhat'] - test_data_N3['y']) * weighted_coeff )/ np.sum(weighted_coeff*test_data_N3['y']) )\n",
    "# print(Wmape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c77822",
   "metadata": {},
   "source": [
    "# Obtenemos Métricas por Hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un solo DF donde se encuentren \n",
    "# Metricstest = pd.concat([test_data_N1,test_data_N2,test_data_N3])\n",
    "Metricstest = test_data_N1\n",
    "# Metricspred = pd.concat([predictions1,predictions2,predictions3])\n",
    "Metricspred = predictions1\n",
    "metrics = pd.concat([Metricstest,Metricspred],axis=1)\n",
    "metrics['Hora'] = metrics.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean nuevos DF los datos de cada hora\n",
    "Hora0 = metrics.loc[metrics.loc[:,'Hora'] == 0]\n",
    "Hora1 = metrics.loc[metrics.loc[:,'Hora'] == 1]\n",
    "Hora2 = metrics.loc[metrics.loc[:,'Hora'] == 2]\n",
    "Hora3 = metrics.loc[metrics.loc[:,'Hora'] == 3]\n",
    "Hora4 = metrics.loc[metrics.loc[:,'Hora'] == 4]\n",
    "Hora5 = metrics.loc[metrics.loc[:,'Hora'] == 5]\n",
    "Hora6 = metrics.loc[metrics.loc[:,'Hora'] == 6]\n",
    "Hora7 = metrics.loc[metrics.loc[:,'Hora'] == 7]\n",
    "Hora8 = metrics.loc[metrics.loc[:,'Hora'] == 8]\n",
    "Hora9 = metrics.loc[metrics.loc[:,'Hora'] == 9]\n",
    "\n",
    "\n",
    "# Se hace ciclo for para calcular RMSE y MAPE. El calculo para cada hora se guarda en un DF diferente\n",
    "for i in range(0,10):    \n",
    "    globals()[f\"Dato{i}\"] = pd.DataFrame(globals()[f\"Hora{i}\"].y.iloc[0],index=[i], columns=['Dato'])\n",
    "for i in range(0,10):    \n",
    "    globals()[f\"Prediccion{i}\"] = pd.DataFrame(globals()[f\"Hora{i}\"].yhat.iloc[0],index=[i], columns=['Predicción'])\n",
    "\n",
    "for i in range(0,10):    \n",
    "    globals()[f\"RMSE{i}\"] = sqrt(mean_squared_error(globals()[f\"Hora{i}\"].y, globals()[f\"Hora{i}\"].yhat))        \n",
    "    globals()[f\"RMSE{i}\"] = pd.DataFrame(globals()[f\"RMSE{i}\"],index=[i], columns=['RMSE'])\n",
    "for i in range(0,10):    \n",
    "    globals()[f\"ErrorAbsoluto{i}\"] = abs((globals()[f\"Hora{i}\"].y) - (globals()[f\"Hora{i}\"].yhat))    \n",
    "    globals()[f\"ErrorAbsoluto{i}\"] = pd.DataFrame(globals()[f\"ErrorAbsoluto{i}\"].iloc[0],index=[i], columns=['ErrorAbsoluto'])              \n",
    "for i in range(0,10): \n",
    "    globals()[f\"PorcentajeError{i}\"] = abs((globals()[f\"Hora{i}\"].y) - (globals()[f\"Hora{i}\"].yhat)) / globals()[f\"Hora{i}\"].y\n",
    "    globals()[f\"PorcentajeError{i}\"] = pd.DataFrame(globals()[f\"PorcentajeError{i}\"].iloc[0],index=[i], columns=['PorcentajeError'])                \n",
    "# for i in range(0,10):    \n",
    "#     globals()[f\"ErrorAbs{i}\"] = float(np.mean(abs((globals()[f\"Hora{i}\"].y) - (globals()[f\"Hora{i}\"].yhat))))                \n",
    "#     globals()[f\"ErrorAbs{i}\"] = pd.DataFrame(globals()[f\"ErrorAbs{i}\"],index=[i], columns=['ErrorAbs-MAE'])        \n",
    "# for i in range(0,10): \n",
    "#     globals()[f\"ErrorPerAbs{i}\"] = float(np.mean((abs((globals()[f\"Hora{i}\"].y) - (globals()[f\"Hora{i}\"].yhat))) / globals()[f\"Hora{i}\"].y))    \n",
    "#     globals()[f\"ErrorPerAbs{i}\"] = pd.DataFrame(globals()[f\"ErrorPerAbs{i}\"],index=[i], columns=['ErrorPerAbs-MAPE'])            \n",
    "for i in range(0,10):\n",
    "    globals()[f\"MAPE{i}\"] = round(np.mean(abs((globals()[f\"Hora{i}\"].y - globals()[f\"Hora{i}\"].yhat)/globals()[f\"Hora{i}\"].y)),4)\n",
    "    globals()[f\"MAPE{i}\"] = pd.DataFrame(globals()[f\"MAPE{i}\"],index=[i], columns=['MAPE'])\n",
    "# for i in range(0,10):\n",
    "#     globals()[f\"SMAPE{i}\"] = round((1/len(globals()[f\"Hora{i}\"]) * np.sum(2*abs((globals()[f\"Hora{i}\"].y - globals()[f\"Hora{i}\"].yhat)) / (abs(globals()[f\"Hora{i}\"].y)+abs(globals()[f\"Hora{i}\"].yhat))*100)),2)\n",
    "#     globals()[f\"SMAPE{i}\"] = pd.DataFrame(globals()[f\"SMAPE{i}\"],index=[i], columns=['SMAPE'])\n",
    "# for i in range(0,10):\n",
    "#     globals()[f\"WMAPE{i}\"] = np.sum(abs(globals()[f\"Hora{i}\"].yhat-globals()[f\"Hora{i}\"].y))/np.sum(abs(globals()[f\"Hora{i}\"].y))*100\n",
    "#     globals()[f\"WMAPE{i}\"] = pd.DataFrame(globals()[f\"WMAPE{i}\"],index=[i], columns=['WMAPE'])\n",
    "# for i in range(0,10):\n",
    "#     globals()[f\"R2{i}\"] = r2_score(globals()[f\"Hora{i}\"].y,globals()[f\"Hora{i}\"].yhat)\n",
    "#     globals()[f\"R2{i}\"] = pd.DataFrame(globals()[f\"R2{i}\"],index=[i], columns=['R2'])\n",
    "\n",
    "# Se concatenan en un solo DF los resultados RMSE y MAPE\n",
    "Dato = pd.concat([Dato0,Dato1,Dato2,Dato3,Dato4,Dato5,Dato6,Dato7,Dato8,Dato9])\n",
    "Prediccion = pd.concat([Prediccion0,Prediccion1,Prediccion2,Prediccion3,Prediccion4,Prediccion5,Prediccion6,Prediccion7,Prediccion8,Prediccion9])\n",
    "\n",
    "ErrorAbsoluto = pd.concat([ErrorAbsoluto0,ErrorAbsoluto1,ErrorAbsoluto2,ErrorAbsoluto3,ErrorAbsoluto4,ErrorAbsoluto5,ErrorAbsoluto6,ErrorAbsoluto7,ErrorAbsoluto8,ErrorAbsoluto9])\n",
    "PorcentajeError = pd.concat([PorcentajeError0,PorcentajeError1,PorcentajeError2,PorcentajeError3,PorcentajeError4,PorcentajeError5,PorcentajeError6,PorcentajeError7,PorcentajeError8,PorcentajeError9])\n",
    "# ErrorAbs = pd.concat([ErrorAbs0,ErrorAbs1,ErrorAbs2,ErrorAbs3,ErrorAbs4,ErrorAbs5,ErrorAbs6,ErrorAbs7,ErrorAbs8,ErrorAbs9])\n",
    "# ErrorPerAbs = pd.concat([ErrorPerAbs0,ErrorPerAbs1,ErrorPerAbs2,ErrorPerAbs3,ErrorPerAbs4,ErrorPerAbs5,ErrorPerAbs6,ErrorPerAbs7,ErrorPerAbs8,ErrorPerAbs9])\n",
    "\n",
    "RMSE = pd.concat([RMSE0,RMSE1,RMSE2,RMSE3,RMSE4,RMSE5,RMSE6,RMSE7,RMSE8,RMSE9])\n",
    "MAPE = pd.concat([MAPE0,MAPE1,MAPE2,MAPE3,MAPE4,MAPE5,MAPE6,MAPE7,MAPE8,MAPE9])\n",
    "# SMAPE = pd.concat([SMAPE0,SMAPE1,SMAPE2,SMAPE3,SMAPE4,SMAPE5,SMAPE6,SMAPE7,SMAPE8,SMAPE9])\n",
    "# WMAPE = pd.concat([WMAPE0,WMAPE1,WMAPE2,WMAPE3,WMAPE4,WMAPE5,WMAPE6,WMAPE7,WMAPE8,WMAPE9])\n",
    "# R2 = pd.concat([R20,R21,R22,R23,R24,R25,R26,R27,R28,R29])\n",
    "\n",
    "# Se concatenan en una sola tabla los resultados de RMSE y MAPE\n",
    "metrics = pd.concat([Dato,Prediccion,ErrorAbsoluto,PorcentajeError],axis=1)\n",
    "# metrics = pd.concat([RMSE,ErrorAbs,ErrorPerAbs,MAPE,SMAPE,WMAPE,R2],axis=1)\n",
    "metrics.index.names = ['Hora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6f7a7",
   "metadata": {},
   "source": [
    "# Nota: Se ajustaron los modelos sin la estacionalidad diaria y se comparó con el modelo Nnormalidad original. Se obtienen resultados diferentes. \n",
    "## Se concluye que la variabilidad de los otros días si está influyendo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
